<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Mini Keras Reference</title>
<style>
  body {
    font-family: Arial, sans-serif;
    margin: 30px;
    background-color: #f5f5f5;
    color: #333;
  }
  h1, h2, h3 {
    color: #222;
  }
  pre {
    background-color: #eee;
    padding: 10px;
    border-left: 4px solid #007acc;
    overflow-x: auto;
  }
  code {
    font-family: monospace;
  }
  table {
    border-collapse: collapse;
    margin: 10px 0;
    width: 100%;
  }
  table, th, td {
    border: 1px solid #ccc;
  }
  th, td {
    padding: 8px;
    text-align: left;
  }
  .note {
    background-color: #fffae6;
    padding: 10px;
    border-left: 4px solid #ffcc00;
  }
</style>
</head>
<body>

<h1>Mini Keras Reference</h1>

<h2>1. Creating a Model</h2>
<p>Sequential model for simple linear regression:</p>
<pre><code>from tensorflow import keras
import numpy as np

# Dataset
x = np.array([[i] for i in range(1, 51)], dtype=float)
y = np.array([2*i for i in range(1, 51)], dtype=float)

# Single neuron linear model
model = keras.Sequential([
    keras.Input(shape=(1,)),
    keras.layers.Dense(1)
])
</code></pre>

<h2>2. Compiling the Model</h2>
<pre><code>optimizer = keras.optimizers.SGD(learning_rate=0.1)
model.compile(optimizer=optimizer, loss="mean_squared_error")
</code></pre>

<h2>3. Training the Model</h2>
<pre><code>model.fit(x, y, epochs=500, verbose=0)</code></pre>

<h2>4. Making Predictions</h2>
<pre><code>pred = model.predict(np.array([[6],[7]]))
print(pred)  # Output: [[12.], [14.]]
</code></pre>

<h2>5. Activations</h2>
<table>
<tr><th>Activation</th><th>Formula</th><th>Use Case</th></tr>
<tr><td>linear</td><td>f(x) = x</td><td>Regression, simple linear models</td></tr>
<tr><td>relu</td><td>f(x) = max(0,x)</td><td>Hidden layers, non-linear relationships</td></tr>
<tr><td>sigmoid</td><td>f(x) = 1 / (1 + exp(-x))</td><td>Binary classification</td></tr>
<tr><td>softmax</td><td>f(x_i) = exp(x_i)/sum(exp(x_j))</td><td>Multi-class classification</td></tr>
</table>

<h2>6. Tips & Best Practices</h2>
<ul>
<li>For linear problems, a single neuron is enough.</li>
<li>Scaling inputs and outputs prevents exploding weights.</li>
<li>Use ReLU or other non-linear activations for hidden layers when modeling complex patterns.</li>
<li>Set learning rate in the optimizer, not in compile.</li>
<li>To reset a model, simply redefine it or use <code>keras.backend.clear_session()</code>.</li>
<li>Keep dataset size and network size proportional to avoid instability.</li>
</ul>

<h2>7. Example: Scaling for Stability</h2>
<pre><code># Scale inputs/outputs
x_scaled = x / 50.0
y_scaled = y / 100.0

# Single neuron linear model
model = keras.Sequential([
    keras.Input(shape=(1,)),
    keras.layers.Dense(1)
])
model.compile(optimizer=keras.optimizers.SGD(learning_rate=0.1),
              loss="mean_squared_error")
model.fit(x_scaled, y_scaled, epochs=500, verbose=0)
</code></pre>

<div class="note">
Note: Scaling is critical when using larger numbers or more neurons; it prevents NaN outputs.
</div>

</body>
</html>
